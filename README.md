# Machine_Learning

## Table of Contents
1. [Informacion Ganeral](#informacion-general)
2. [Tecnologia](#tecnologia)
3. [Paso a Paso](#paso-a-paso)
3. [Colaboraciones](#colaboraciones)
4. [FAQs](#faqs)
### Información General
***
Realizando una definición del problema encontramos que debemos hacer un modelo predictivo para nuestra Empresa, bajo los estándares de la compañía un modelo que pueda predecir si una propiedad está por debajo de los estándares de nivel bajo, para esto implementaremos un modelo supervisado para definir las mejores alternativas de nuestro proyecto predictivo a continuación haremos una breve descripción de los implementos y tecnologías que utilizamos para realizar este Proyecto

![Image text](https://www.united-internet.de/fileadmin/user_upload/Brands/Downloads/Logo_IONOS_by.jpg)

## Tecnologias
***
Una Lista de las tecnologias utilizadas:
* [Python](https://example.com): Version 3.10
* [Pandas](https://example.com): Version 1.5
* [Numpy](https://example.com): Version 1.24
* [pyarrow](https://example.com): Version 10.0.1
* [scikit-learn](https://example.com): Version 1.2.0
* [seaborn](https://example.com): Version 0.12.2
* [matplotlib](https://example.com): Version 0.1.6


## Paso a Paso
***
Realizaremos una breve descripción del paso a paso que realizamos para poder llegar a nuestro modelo predictivo

### Realizamos exploracion 
Lo primero que debemos hacer es una exploración inicial de nuestros datos para mirar cómo se encuentra el Dataset, después de hacer una breve introducción al Dataset y verificar nuestra información pasaremos tomaremos las mejores decisiones para los procesos a realizar.

### Transformaciones inicialies

Procederemos a eliminar las columnas que no sean efectivas para nuestro modelo, después de esto y haremos una visualización de los valores nulos y duplicados que tengamos en nuestro Dataset, para tomar la decisión de eliminarlos o imputarlos.
### Verificacionn de Outliers

Después procederemos a realizar una verificación de outliers y datos atipicos para visualizar si hay valores por fuera de los rangos previstos o que necesitemos validar.

### Normalizaciones

Después de esto pasaremos a realizar normalizaciones de variables estoy realizando un proceso de LavelEncoder o OneHotEncoder el cual hace una transformación de nuestras variables categóricas por valores de números para poder procesar mucho mejor nuestro modelo.

Verificamos que nuestra variable objetivo se encuentre balanceada para que no haya sesgos en las predicciones 

Realizamos un mapa de calor para verificar la correlación de nuestras variables y poder tomar una decisión de qué variables utilizar para nuestro modelo predictivo, hacemos la discretización de nuestras variables objetivo y nuestras variables a presidir 

### Verificación de modelos 

Realizaremos validaciones para verificar qué modelo de predicción se ajusta más a nuestro proyecto después de hacer validaciones vamos a otorgar un entrenamiento de testeo para poder predecir nuestras variables objetivo

Y pasamos a tener un modelo predictivo

En [Analisis_Datos](https://github.com/Alemax019/Machine_Learning/blob/main/Analisis_Datos.ipynb) y [árbol](https://github.com/Alemax019/Machine_Learning/blob/main/Arbol.ipynb) estará más detallado todo el proceso

## Colaboraciones
***
Agradecimiento a nuestros instructores y compañeros que nos aportan deferentes ideas y conocimientos para continuar con nuestro proceso

## FAQs

Todo nuestro proyecto se encuentra en 
* Git link(https://github.com/Alemax019/Machine_Learning)
* LinkedIn(https://www.linkedin.com/in/cristiangarcia019)
